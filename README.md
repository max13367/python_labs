# python_labs

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1

### –ó–∞–¥–∞–Ω–∏–µ 1

```
name = input()
age = int(input())
print(f"–ü—Ä–∏–≤–µ—Ç, {name}! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç {age + 1}.")
```

![—Ñ–æ—Ç–æ1](./images/lab01/01.png)


### –ó–∞–¥–∞–Ω–∏–µ 2

```
a = float(input().replace(',', '.'))
b = float(input().replace(',', '.'))
sum_ = a + b
avg_ = sum_ / 2
print(f"sum={sum_:.2f}; avg={avg_:.2f}")
```

![—Ñ–æ—Ç–æ2](./images/lab01/02.png)


### –ó–∞–¥–∞–Ω–∏–µ 3

```
price = int(input())
discount = int(input())
vat = int(input())

base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount

print(f"–ë–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏: {base:.2f} $")
print(f"–ù–¥—Å              : {vat_amount:.2f} $")
print(f"–ò—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ   : {total:.2f} $")
```

![—Ñ–æ—Ç–æ3](./images/lab01/03.png)



### –ó–∞–¥–∞–Ω–∏–µ 4

```
m = int(input())

hours = m // 60
minutes = m % 60

print(f"{hours}:{minutes:02d}")
```

![—Ñ–æ—Ç–æ4](./images/lab01/04.png)


### –ó–∞–¥–∞–Ω–∏–µ 5

```
fio_input = input()
fio_new = ' '.join(fio_input.split())

words = fio_new.split()

initials = ''.join([word[0].upper() for word in words])

length = len(fio_new)

print(f"–§–ò–û             : {fio_input}")
print(f"–ò–Ω–∏—Ü–∏–∞–ª—ã        : {initials}.")
print(f"–î–ª–∏–Ω–∞ (—Å–∏–º–≤–æ–ª–æ–≤): {length}")
```

![—Ñ–æ—Ç–æ5](./images/lab01/05.png)


### –ó–∞–¥–∞–Ω–∏–µ 6

```
n = int(input())
ochn = 0
zaochn = 0
for i in range(n):
    name = input().split()
    if 'True' in name:
        ochn += 1
    else:
        zaochn += 1
print(ochn, zaochn)
```

![—Ñ–æ—Ç–æ6](./images/lab01/06.png)


### –ó–∞–¥–∞–Ω–∏–µ 7

```
str_ = str(input())

newstr_ = ''
index_first = -1
index_second = -1
index_last = -1

for i in str_:
    index_first += 1
    if i.isupper():
        break

for i in range(len(str_) - 1):
    if str_[i].isdigit():
        index_second = i + 1
        break

for i in str_:
    index_last += 1
    if i == '.':
        break
        

shag = index_second - index_first

for i in range(index_first, index_last + 1, shag):
    newstr_ += str_[i]
print(newstr_)
```

![—Ñ–æ—Ç–æ7](./images/lab01/07.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2

### –ó–∞–¥–∞–Ω–∏–µ 1

```
def min_max(a):
    if not a:
        return 'ValueError'

    max_ = -10 ** 10
    min_ = 10 ** 10
    for i in a:
        if i > max_:
            max_ = i
        if i < min_:
            min_ = i

    return (min_, max_)


def unique_sorted(b):
    return sorted(set(b))


def flatten(c):
    if not c:
        return []

    result = []

    for i in c:
        if not isinstance(i, (list, tuple)):
            return 'TypeError'
        result.extend(i)

    return result
```

![—Ñ–æ—Ç–æ1 2](./images/lab02/01.png)


### –ó–∞–¥–∞–Ω–∏–µ 2

```
def transpose(a):
    if not a:
        return []

    first_riad = len(a[0])
    for i in a:
        if len(i) != first_riad:
            return 'ValueError'

    result = []
    for stolb in range(len(a[0])):
        new_riad = []
        for riad in range(len(a)):
            new_riad.append(a[riad][stolb])
        result.append(new_riad)

    return result

def row_sums(b):
    if not b:
        return []

    first_riad = len(b[0])
    for i in b:
        if len(i) != first_riad:
            return 'ValueError'

    result = []
    for row in b:
        result.append(sum(row))
    return result

def col_sums(c):
    if not c:
        return []

    first_riad = len(c[0])
    for i in c:
        if len(i) != first_riad:
            return 'ValueError'

    result = []
    for stolb in range(len(c[0])):
        sum_ = 0
        for riad in range(len(c)):
            sum_ += c[riad][stolb]
        result.append(sum_)

    return result
```

![—Ñ–æ—Ç–æ2 2](./images/lab02/02.png)


### –ó–∞–¥–∞–Ω–∏–µ 3

```
def format_record(rec: tuple[str, str, float]) -> str:
    student, gruppa, gpa = rec
    
    if not isinstance(gpa, (int, float)):
        raise TypeError("GPA –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–º")

    if not student or not student.strip():
        raise ValueError("–§–ò–û —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

    if not gruppa or not gruppa.strip():
        raise ValueError("–ù–æ–º–µ—Ä –≥—Ä—É–ø–ø—ã –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")


    student = student.strip().title()
    parts = [part for part in student.split() if part]


    if len(parts) < 1:
        raise ValueError("–§–ò–û –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ö–æ—Ç—è –±—ã —Ñ–∞–º–∏–ª–∏—é")

    student = student.title()
    parts = student.split()
    familiya = parts[0]
    new_fam = []
    if len(parts) > 1:
        new_fam.append(parts[1])
    if len(parts) > 2:
        new_fam.append(parts[2])

    initial = []
    for i in new_fam:
        initial.append(i[0] + '.')


    initials_str = ''.join(initial)
    fio = f'{familiya} {initials_str}, –≥—Ä. {gruppa}, GPA {gpa:.2f}'
    return fio
```

![—Ñ–æ—Ç–æ3 2](./images/lab02/03.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3

### –ó–∞–¥–∞–Ω–∏–µ 1

```
import re
from collections import Counter
from typing import Dict, List, Tuple

def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if yo2e:
        text = text.replace("—ë", "–µ").replace("–Å", "–ï")
    if casefold:
        text = text.casefold()
    text = re.compile(r"[\t\r\n]+").sub(" ", text)
    text = re.compile(r"\s+").sub(" ", text).strip()
    return text

def tokenize(text: str) -> List[str]:
    return re.compile(r"[^\W_]+(?:-[^\W_]+)*", flags=re.UNICODE).findall(text)

def count_freq(tokens: List[str]) -> Dict[str, int]:
    return dict(Counter(tokens))

def top_n(freq: Dict[str, int], n: int = 5) -> List[Tuple[str, int]]:
    if n <= 0:
        return []
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))[:n]
```

![—Ñ–æ—Ç–æ1 3](./images/lab03/01.png)

### –ó–∞–¥–∞–Ω–∏–µ 2

```
from __future__ import annotations

import sys
from pathlib import Path

sys.path.append(str(Path(__file__).resolve().parents[1]))

from lib.text import normalize, tokenize, count_freq, top_n


def main() -> None:
    data = sys.stdin.read()

    norm = normalize(data)
    tokens = tokenize(norm)
    freq = count_freq(tokens)
    top = top_n(freq, n=5)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")
    print("–¢–æ–ø-5:")
    for word, cnt in top:
        print(f"{word}:{cnt}")


if __name__ == "__main__":
    main()
```

![—Ñ–æ—Ç–æ2 3](./images/lab03/02.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4

### –ó–∞–¥–∞–Ω–∏–µ 1

```
from pathlib import Path
import csv
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """–°—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ .txt —Ñ–∞–π–ª–∞"""
    p = Path(path)
    if p.suffix.lower() != ".txt":
        raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º txt.")
    try:
        return p.read_text(encoding=encoding)
    except FileNotFoundError:
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {p}")
    except UnicodeDecodeError:
        raise UnicodeDecodeError("–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É.")


def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    if p.suffix.lower() != ".csv":
        raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .csv")

    rows = list(rows)
    if rows:
        length = len(rows[0])
        for r in rows:
            if len(r) != length:
                raise ValueError("–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É")

    if header is not None and rows:
        if len(header) != len(rows[0]):
            raise ValueError("–î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–ª–∏–Ω–æ–π —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)

# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞–Ω–∏—è

if __name__ == "__main__":
    # –ó–∞–¥–∞–Ω–∏–µ A
    Path("data").mkdir(exist_ok=True)
    (Path("data") / "input.txt").write_text("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!", encoding="utf-8")
    print("–§–∞–π–ª data/input.txt —Å–æ–∑–¥–∞–Ω")

    # –ó–∞–¥–∞–Ω–∏–µ B
    def print_csv(path):
        p = Path(path)
        with p.open('r', encoding='utf-8') as f:
            for line in f:
                print(line.strip())

    write_csv([], "data/empty.csv", header=("a", "b"))
    print_csv("data/empty.csv")

    write_csv([("word", "count"), ("test", 3)], "data/check.csv")
    print_csv("data/check.csv")

    txt = read_text(Path("data") / "input.txt")
    print("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ input.txt:", txt)
    csv_path = Path("data") / "report.csv"
    write_csv([("word", "count"), ("–ø—Ä–∏–≤–µ—Ç", 2)], csv_path, header=("word", "count"))
    print("–°–æ–∑–¥–∞–Ω CSV:", csv_path)

    try:
        (Path("data") / "1251input.txt").write_text("–ü—Ä–∏–≤–µ—Ç –∏–∑ cp1251", encoding="cp1251")
        str_cp1251 = read_text("data/1251input.txt", encoding='cp1251')
        print("–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –∏–∑ cp1251:", str_cp1251)
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ cp1251 —Ñ–∞–π–ª–∞:", e)
```


### –ü—Ä–∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö —á–∏—Ç–∞–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, –Ω–µ –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞—è –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–æ–∫

```
def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    if p.suffix.lower() != ".csv":
        raise ValueError("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .csv")

    rows = list(rows)
    if rows:
        length = len(rows[0])
        for r in rows:
            if len(r) != length:
                raise ValueError("–í—Å–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É")

    if header is not None and rows:
        if len(header) != len(rows[0]):
            raise ValueError("–î–ª–∏–Ω–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –¥–ª–∏–Ω–æ–π —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)
```
### –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ data –∏ —Ñ–∞–π–ª–∞ input.txt
```
from pathlib import Path
Path("data").mkdir(exist_ok=True)
Path("data")/ "input.txt".write_text("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!", encoding="utf-8")
csv_path = Path("data") / "check.csv"
write_csv([("word", "count"), ("test", 3)], csv_path)
print(csv_path)

```
### –ß—Ç–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ 1251
```
    try:
        (Path("data") / "1251input.txt").write_text("–ü—Ä–∏–≤–µ—Ç –∏–∑ cp1251", encoding="cp1251")
        str_cp1251 = read_text("data/1251input.txt", encoding='cp1251')
        print("–ü—Ä–æ—á–∏—Ç–∞–Ω–æ –∏–∑ cp1251:", str_cp1251)
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ cp1251 —Ñ–∞–π–ª–∞:", e)
```
![—Ñ–æ—Ç–æ1 4](./images/lab04/04.png)

### –ß—Ç–µ–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
![—Ñ–æ—Ç–æ1 4](./images/lab04/03.png)

### –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –¥—Ä—É–≥–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ
![—Ñ–æ—Ç–æ1 4](./images/lab04/05.png)

### –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
![—Ñ–æ—Ç–æ1 4](./images/lab04/06.png)

### –ó–∞–¥–∞–Ω–∏–µ 2
```
from pathlib import Path
from collections import Counter
from src.lib.text import normalize, tokenize, top_n
from src.lab04.io_txt_csv import read_text, write_csv

try:
    text = read_text(Path("data/input.txt"))
except FileNotFoundError:
    print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {Path('data/input.txt')}")
    raise
except UnicodeDecodeError:
    print(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {Path('data/input.txt')}")
    raise

def frequencies_from_text(text: str) -> dict[str, int]:
    from src.lib.text import normalize, tokenize, top_n  # –∏–∑ –õ–†3
    tokens = tokenize(normalize(text))
    return Counter(tokens)

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))

tekst = read_text("data/input.txt")

tokens = tokenize(normalize(tekst))
count = Counter(tokens)

sorted_freq = sorted_word_counts(count)

csv_path = Path("data") / "report.csv"
write_csv(sorted_freq, csv_path, header=("word", "count"))
print("–°–æ–∑–¥–∞–Ω CSV:", csv_path)

print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(count)}")
print(f"–¢–æ–ø-5:")
for word, col in sorted_freq[:5]:
    print(f"{word}: {col}")
```
![—Ñ–æ—Ç–æ1 4](./images/lab04/01.png)
![—Ñ–æ—Ç–æ1 4](./images/lab04/02.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5

### –ó–∞–¥–∞–Ω–∏–µ 1

```
from pathlib import Path
import json
import csv

def json_to_csv(json_path: str, csv_path: str) -> None:
    p_json = Path(json_path)
    p_csv = Path(csv_path)

    if p_json.suffix.lower() != ".json":
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .json")
    if p_csv.suffix.lower() != ".csv":
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .csv")

    if not p_json.exists():
        raise FileNotFoundError("–§–∞–π–ª JSON –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if not p_csv.parent.exists():
        raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è CSV –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    try:
        data = json.loads(p_json.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        raise ValueError("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON")

    if not data or not isinstance(data, list):
        raise ValueError("–ü—É—Å—Ç–æ–π JSON")
    if not all(isinstance(item, dict) for item in data):
        raise ValueError("JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª—é—á–∏
    keys = list(data[0].keys())
    for d in data[1:]:
        for k in d.keys():
            if k not in keys:
                keys.append(k)

    # –ó–∞–ø–∏—Å—å CSV
    with p_csv.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        for row in data:
            writer.writerow({k: row.get(k, "") for k in keys})

    with p_csv.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        csv_data = list(reader)
        if len(csv_data) != len(data):
            raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")


def csv_to_json(csv_path: str, json_path: str) -> None:
    p_csv = Path(csv_path)
    p_json = Path(json_path)

    if p_csv.suffix.lower() != ".csv":
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .csv")
    if p_json.suffix.lower() != ".json":
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .json")

    if not p_csv.exists():
        raise FileNotFoundError("–§–∞–π–ª CSV –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if not p_json.parent.exists():
        raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è JSON –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    # –ß—Ç–µ–Ω–∏–µ CSV
    with p_csv.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        if not reader.fieldnames:
            raise ValueError("CSV –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫")
        data = [row for row in reader]

    if not data:
        raise ValueError("CSV –ø—É—Å—Ç–æ–π")

    # –ó–∞–ø–∏—Å—å JSON
    with p_json.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    reread = json.loads(p_json.read_text(encoding="utf-8"))
    if len(reread) != len(data):
        raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
```
### –û—à–∏–±–∫–∏ 
#### –ü—É—Å—Ç–æ–π json
![—Ñ–æ—Ç–æ1 5](./images/lab05/01.png)
#### –î—Ä—É–≥–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(–Ω–µ json)
![—Ñ–æ—Ç–æ1 5](./images/lab05/02.png)
#### –ù–µ—Ç—É —Ñ–∞–π–ª–∞ json
![—Ñ–æ—Ç–æ1 5](./images/lab05/03.png)
#### –î—Ä—É–≥–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(–Ω–µ csv)
![—Ñ–æ—Ç–æ1 5](./images/lab05/04.png)
#### –ù–µ—Ç—É –∑–∞–≥–∞–ª–æ–≤–∫–∞ csv
![—Ñ–æ—Ç–æ1 5](./images/lab05/05.png)
#### –ù–µ—Ç—É —Ñ–∞–π–ª–∞ csv
![—Ñ–æ—Ç–æ1 5](./images/lab05/07.png)
#### json –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
![—Ñ–æ—Ç–æ1 5](./images/lab05/08.png)

### –ó–∞–¥–∞–Ω–∏–µ 2

```
from pathlib import Path
import csv
from openpyxl import Workbook

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    p_csv = Path(csv_path)
    p_xlsx = Path(xlsx_path)
    # –ü—Ä–æ–≤–µ—Ä–∫–∏ –ø—É—Ç–µ–π
    if p_csv.suffix.lower() != ".csv":
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .csv")
    if p_xlsx.suffix.lower() != ".xlsx":
        raise ValueError("–û–∂–∏–¥–∞–µ—Ç—Å—è —Ñ–∞–π–ª —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .xlsx")

    if not p_csv.exists():
        raise FileNotFoundError("–§–∞–π–ª CSV –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –ß—Ç–µ–Ω–∏–µ CSV
    with p_csv.open("r", encoding="utf-8", newline="") as f:
        reader = csv.reader(f)
        rows = list(reader)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
    if not rows or all(not any(row) for row in rows):
        raise ValueError("–ü—É—Å—Ç–æ–π CSV –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")

    # –°–æ–∑–¥–∞–Ω–∏–µ XLS
    wb = Workbook()
    ws = wb.active
    ws.title = "Sheet1"

    for row in rows:
        ws.append(row)

    # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞
    for col in ws.columns:
        max_len = max(len(str(cell.value or "")) for cell in col)
        col_letter = col[0].column_letter
        ws.column_dimensions[col_letter].width = max(max_len + 2, 8)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
    if not p_xlsx.parent.exists():
        raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è XLSX –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    wb.save(p_xlsx)
#–ü–†–ò–ú–ï–†
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è people.csv ‚Üí people.xlsx
csv_to_xlsx("data2/samples/people.csv", "data2/out/people1.xlsx")

csv_input = Path("data2/samples/cities.csv")
xlsx_output = Path("data2/out/cities.xlsx")

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É out, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
xlsx_output.parent.mkdir(parents=True, exist_ok=True)
csv_input.parent.mkdir(parents=True, exist_ok=True)

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä –≤ CSV
example_rows = [
    ["city", "country", "language"],
    ["Moscow", "Russia", "Russian"],
    ["Tokyo", "Japan", "Japanese"],
    ["Paris", "France", "French"],
]
with csv_input.open("w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerows(example_rows)

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è CSV ‚Üí XLSX
csv_to_xlsx(csv_input, xlsx_output)

csv_to_xlsx("data2/samples/people_empty.csv", "data2/samples/people2.xlsx")
#csv_to_xlsx("data2/samples/people_NO_file.csv", "data/samples/people3.xlsx")
#csv_to_xlsx("data2/samples/tupy.csv", "data/samples/people3.json")

```
### –û—à–∏–±–∫–∏ 
#### –ü—É—Å—Ç–æ–π csv
![—Ñ–æ—Ç–æ1 5](./images/lab05/09.png)
#### –ù–µ—Ç—É —Ñ–∞–π–ª–∞ csv
![—Ñ–æ—Ç–æ1 5](./images/lab05/10.png)
#### –î—Ä—É–≥–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ(–Ω–µ xlsx)
![—Ñ–æ—Ç–æ1 5](./images/lab05/11.png)

### –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã json_csv
![—Ñ–æ—Ç–æ1 5](./images/lab05/12.png)
![—Ñ–æ—Ç–æ1 5](./images/lab05/13.png)

### –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã csv_xlsx
![—Ñ–æ—Ç–æ1 5](./images/lab05/14.png)
![—Ñ–æ—Ç–æ1 5](./images/lab05/15.png)


## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6

### –ó–∞–¥–∞–Ω–∏–µ 1

```
import argparse
import os
from src.lab05.json_csv import json_to_csv, csv_to_json
from src.lab05.csv_xlsx import csv_to_xlsx


def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö")
    commands = parser.add_subparsers(dest="action", required=True)

    # JSON ‚Üí CSV
    c_json = commands.add_parser("json2csv", help="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å JSON –≤ CSV")
    c_json.add_argument("--in", dest="src", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    c_json.add_argument("--out", dest="dst", required=True, help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å CSV")

    # CSV ‚Üí JSON
    c_csv = commands.add_parser("csv2json", help="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å CSV –≤ JSON")
    c_csv.add_argument("--in", dest="src", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    c_csv.add_argument("--out", dest="dst", required=True, help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å JSON")

    # CSV ‚Üí XLSX
    c_xlsx = commands.add_parser("csv2xlsx", help="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å CSV –≤ XLSX")
    c_xlsx.add_argument("--in", dest="src", required=True, help="–í—Ö–æ–¥–Ω–æ–π CSV —Ñ–∞–π–ª")
    c_xlsx.add_argument("--out", dest="dst", required=True, help="–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å XLSX")

    opts = parser.parse_args()

    if not os.path.isfile(opts.src):
        raise FileNotFoundError(f"–§–∞–π–ª '{opts.src}' –Ω–µ –Ω–∞–π–¥–µ–Ω")

    if opts.action == "json2csv":
        json_to_csv(opts.src, opts.dst)
    elif opts.action == "csv2json":
        csv_to_json(opts.src, opts.dst)
    elif opts.action == "csv2xlsx":
        csv_to_xlsx(opts.src, opts.dst)
    else:
        parser.error("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è")


if __name__ == "__main__":
    main()

```
### –ó–∞–¥–∞–Ω–∏–µ 2

```
import argparse
from src.lib.text import tokenize, count_freq, top_n


def main():
    parser = argparse.ArgumentParser(description="–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏")
    cmds = parser.add_subparsers(dest="mode")

    # cat
    cmd_cat = cmds.add_parser("cat", help="–ü–æ–∫–∞–∑–∞—Ç—å —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º")
    cmd_cat.add_argument("--file", required=True, help="–§–∞–π–ª –¥–ª—è —á—Ç–µ–Ω–∏—è")
    cmd_cat.add_argument("-n", "--nums", action="store_true", help="–í—ã–≤–æ–¥–∏—Ç—å –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫")

    # stats
    cmd_stats = cmds.add_parser("stats", help="–ü–æ–¥—Å—á—ë—Ç –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Å–ª–æ–≤")
    cmd_stats.add_argument("--file", required=True, help="–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
    cmd_stats.add_argument("--k", type=int, default=5, help="–°–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤—ã–≤–µ—Å—Ç–∏")

    opt = parser.parse_args()

    if opt.mode == "cat":
        with open(opt.file, encoding="utf-8") as fh:
            for idx, line in enumerate(fh, 1):
                line = line.rstrip()
                print(f"{idx}: {line}" if opt.nums else line)

    elif opt.mode == "stats":
        with open(opt.file, encoding="utf-8") as fh:
            data = fh.read()
        words = tokenize(data)
        freq = count_freq(words)
        for w, c in top_n(freq, opt.k):
            print(f"{w}: {c}")


if __name__ == "__main__":
    main()
```
### –¢–µ—Å—Ç—ã
#### –¢–µ–∫—Å—Ç —Å –Ω–æ–º–µ—Ä–∞–º–∏ —Å—Ç—Ä–æ–∫
![—Ñ–æ—Ç–æ1 6](./images/lab06/01.png)
![—Ñ–æ—Ç–æ1 6](./images/lab06/02.png)
#### –¢–µ–∫—Å—Ç —Å —Ç–æ–ø–æ–º —Å–ª–æ–≤
![—Ñ–æ—Ç–æ1 6](./images/lab06/03.png)
#### –ü–æ–º–æ—â—å –ø–æ –∫–æ–º–∞–Ω–¥–∞–º
![—Ñ–æ—Ç–æ1 6](./images/lab06/04.png)
![—Ñ–æ—Ç–æ1 6](./images/lab06/05.png)
#### –¢–µ—Å—Ç—ã –ø–æ –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞–º
![—Ñ–æ—Ç–æ1 6](./images/lab06/06.png)
![—Ñ–æ—Ç–æ1 6](./images/lab06/07.png)
![—Ñ–æ—Ç–æ1 6](./images/lab06/08.png)
#### –û—à–∏–±–∫–∏
![—Ñ–æ—Ç–æ1 6](./images/lab06/09.png)
![—Ñ–æ—Ç–æ1 6](./images/lab06/10.png)

## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7

### –ó–∞–¥–∞–Ω–∏–µ 1

```
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n


# ------------------------- normalize -------------------------


@pytest.mark.parametrize(
    "src,expected",
    [
        ("HeLlo WOrld", "hello world"),
        ("", ""),
        ("TEST", "test"),
        ("Hello\tWorld", "hello world"),
        ("–ü–†–∏–≤–µ—Ç\n–ú–ò—Ä\t\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫, –µ–ª–∫–∞"),
    ],
)
def test_normalize_parametrized(src, expected):
    assert normalize(src) == expected


def test_normalize_control_characters_removed():
    raw = "Hello\tWorld\nTest"
    out = normalize(raw)

    assert "\t" not in out
    assert "\n" not in out
    assert "  " not in out


def test_normalize_yo_to_e():
    text = "—ë–∂–∏–∫ —ë–ª–∫–∞ –Å–ª–∫–∞ –Å–∂–∏–∫"
    assert normalize(text) == "–µ–∂–∏–∫ –µ–ª–∫–∞ –µ–ª–∫–∞ –µ–∂–∏–∫"


# ------------------------- tokenize -------------------------


@pytest.mark.parametrize(
    "src,expected",
    [
        ("hello world test", ["hello", "world", "test"]),
        ("", []),
        ("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ", ["emoji", "–Ω–µ", "—Å–ª–æ–≤–æ"]),
        ("Meow_meow-", ["Meow_meow"]),
        ("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ", ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]),
    ],
)
def test_tokenize_parametrized(src, expected):
    assert tokenize(src) == expected


# ------------------------- count_freq -------------------------


@pytest.mark.parametrize(
    "tokens,expected",
    [
        (["a", "b", "a", "c", "b", "a"], {"a": 3, "b": 2, "c": 1}),
        ([" "], {" ": 1}),
        (
            ["bb", "aa", "bb", "aa", "cc"],
            {"aa": 2, "bb": 2, "cc": 1},
        ),
        ([], {}),
        (
            ["a", "a", "b", "b", "c", "c", "1", "1", "f", "f", "f"],
            {"1": 2, "a": 2, "b": 2, "c": 2, "f": 3},
        ),
    ],
)
def test_count_freq(tokens, expected):
    assert count_freq(tokens) == expected


# ------------------------- top_n -------------------------


def test_top_n_basic():
    freq = {"apple": 5, "banana": 3, "orange": 4, "grape": 2}
    out = top_n(freq, 3)
    assert out == [("apple", 5), ("orange", 4), ("banana", 3)]


def test_top_n_tie_breaker_alphabetical():
    freq = {"banana": 3, "apple": 3, "cherry": 3, "date": 2}
    out = top_n(freq, 3)
    assert out == [("apple", 3), ("banana", 3), ("cherry", 3)]


def test_top_n_request_more_than_available():
    freq = {"apple": 3, "banana": 2}
    out = top_n(freq, 5)
    assert out == [("apple", 3), ("banana", 2)]


def test_top_n_zero_returns_empty():
    assert top_n({"apple": 3, "banana": 2}, 0) == []


@pytest.mark.parametrize(
    "freq,n,expected",
    [
        ({}, 5, []),
        ({"a": 1}, 0, []),
        ({"a": 2, "b": 1}, 2, [("a", 2), ("b", 1)]),
        ({"b": 1, "a": 1}, 2, [("a", 1), ("b", 1)]),
    ],
)
def test_top_n_parametrized(freq, n, expected):
    t top_n(freq, n) == expected
```![img.png](img.png)
![—Ñ–æ—Ç–æ1 7](./images/lab07/01.png)
```
![—Ñ–æ—Ç–æ1 7](./images/lab07/01.png)
### –ó–∞–¥–∞–Ω–∏–µ 2

```
import json
from pathlib import Path
import csv
import pytest


from src.lab05.json_csv import json_to_csv, csv_to_json


# ------------------------- JSON ‚Üí CSV -------------------------


def test_json_to_csv_success(tmp_path):
    """–ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON ‚Üí –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π CSV"""
    source_data = [
        {"name": "Alice", "age": 30, "city": "New York"},
        {"name": "Bob", "age": 25, "city": "London"},
    ]

    src = tmp_path / "src.json"
    dst = tmp_path / "result.csv"

    src.write_text(json.dumps(source_data, ensure_ascii=False, indent=2), encoding="utf-8")

    json_to_csv(str(src), str(dst))
    assert dst.exists()

    with open(dst, encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert rows[0]["name"] == "Alice"
    assert rows[0]["age"] == "30"
    assert rows[0]["city"] == "New York"
    assert rows[1]["name"] == "Bob"


def test_json_to_csv_nonexistent():
    """–û—à–∏–±–∫–∞: –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
    with pytest.raises(FileNotFoundError):
        json_to_csv("missing_file.json", "out.csv")


def test_json_to_csv_broken_json(tmp_path):
    """–û—à–∏–±–∫–∞: JSON –ø–æ–≤—Ä–µ–∂–¥—ë–Ω"""
    p = tmp_path / "invalid.json"
    p.write_text("{ broken json }", encoding="utf-8")

    with pytest.raises(ValueError):
        json_to_csv(str(p), "output.csv")


# ------------------------- CSV ‚Üí JSON -------------------------


def test_csv_to_json_success(tmp_path):
    csv_data = [
        ["name", "age", "city"],
        ["Alice", "30", "New York"],
        ["Bob", "25", "London"],
    ]

    src = tmp_path / "src.csv"
    dst = tmp_path / "res.json"

    with open(src, "w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerows(csv_data)

    csv_to_json(str(src), str(dst))
    assert dst.exists()

    with open(dst, encoding="utf-8") as f:
        parsed = json.load(f)

    assert len(parsed) == 2
    assert parsed[0] == {"name": "Alice", "age": "30", "city": "New York"}


def test_csv_to_json_missing_file():
    with pytest.raises(FileNotFoundError):
        csv_to_json("not_exists.csv", "result.json")


def test_csv_to_json_invalid(tmp_path):
    """–û—à–∏–±–∫–∞: –ø—É—Å—Ç–æ–π CSV"""
    csv_file = tmp_path / "empty.csv"
    csv_file.write_text("", encoding="utf-8")

    with pytest.raises(ValueError):
        csv_to_json(str(csv_file), "output.json")
```
![—Ñ–æ—Ç–æ1 7](./images/lab07/02.png)

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–ª—è –Ω–∞ black
![—Ñ–æ—Ç–æ1 7](./images/lab07/03.png)

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Å—Ç–æ–≤ —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º 
![—Ñ–æ—Ç–æ1 7](./images/lab07/04.png)